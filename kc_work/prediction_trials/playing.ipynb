{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport prediction_models\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import nltk\n",
    "import copy\n",
    "import random\n",
    "from collections import Counter\n",
    "import operator\n",
    "import math\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead, AutoModelForSequenceClassification, pipeline, T5ForConditionalGeneration, T5Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ICT2000/chawla/anaconda3/envs/base_acii/lib/python3.7/site-packages/transformers/models/auto/modeling_auto.py:1010: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/t5-base-finetuned-emotion\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\"mrm8488/t5-base-finetuned-emotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text i have a feeling i kinda lost my best friend\n",
      "input_ids tensor([[   3,   23,   43,    3,    9, 1829,    3,   23,  773,    9, 1513,   82,\n",
      "          200, 1565,    1]])\n",
      "output tensor([[    0, 24784]])\n",
      "dec ['<pad> sadness']\n",
      "label sadness\n"
     ]
    }
   ],
   "source": [
    "text = 'i have a feeling i kinda lost my best friend'\n",
    "print(\"text\", text)\n",
    "\n",
    "input_ids = tokenizer.encode(text + '</s>', return_tensors='pt')\n",
    "print(\"input_ids\", input_ids)\n",
    "\n",
    "output = model.generate(input_ids=input_ids, max_length=2)\n",
    "print(\"output\", output)\n",
    "\n",
    "dec = [tokenizer.decode(ids) for ids in output]\n",
    "print(\"dec\", dec)\n",
    "\n",
    "label = dec[0].split()[-1]\n",
    "print(\"label\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text i am very happy\n",
      "input_ids tensor([[   3,   23,  183,  182, 1095,    1]])\n"
     ]
    }
   ],
   "source": [
    "text = 'i am very happy'\n",
    "print(\"text\", text)\n",
    "\n",
    "input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "print(\"input_ids\", input_ids)\n",
    "\n",
    "#outputs = model(input_ids=input_ids, decoder_input_ids=input_ids, return_dict=True, output_attentions=True, output_hidden_states=True)\n",
    "\n",
    "output = model.generate(input_ids=input_ids, max_length=2, output_scores=True, output_hidden_states=True, output_attentions=True, return_dict_in_generate=True)\n",
    "#print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-20.1368, -12.3730, -13.3437,  ..., -45.1157, -44.9564, -44.8964])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['scores'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3922, 11213, 24784, 333, 2971, 4158]\n"
     ]
    }
   ],
   "source": [
    "labels = ['joy', 'anger', 'sadness', 'love', 'fear', 'surprise']\n",
    "ixs = []\n",
    "for label in labels:\n",
    "    ixs.append(tokenizer.encode(label)[0])\n",
    "print(ixs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['sequences', 'scores', 'encoder_attentions', 'encoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'decoder_hidden_states'])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sadness'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([24784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
