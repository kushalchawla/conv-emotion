{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGather the utterances...and make emotion predictions...look at them...\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Gather the utterances...and make emotion predictions...look at them...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport prediction_models\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import nltk\n",
    "import copy\n",
    "import random\n",
    "from collections import Counter\n",
    "import operator\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030\n",
      "dict_keys(['convo_is_finished', 'world_tag', 'bad_workers', 'acts', 'turns', 'workers', 'fpath', 'qualtrics', 'dialogue_id'])\n"
     ]
    }
   ],
   "source": [
    "in_f = \"/home/ICT2000/chawla/Documents/internship2020/git_repo/storage/airtable/all_data-1030-shuffled.json\" \n",
    "with open(in_f) as f:\n",
    "    all_data = json.load(f)\n",
    "    \n",
    "print(len(all_data))\n",
    "print(all_data[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_utterances(item):\n",
    "    \n",
    "    utterances = []\n",
    "    \n",
    "    for act in item['acts']:\n",
    "        \n",
    "        if (act['text'] not in ['Submit-Deal', 'Accept-Deal', 'Reject-Deal', 'Walk-Away', 'Submit-Post-Survey']):\n",
    "            utterances.append(act['text'])\n",
    "            \n",
    "    return utterances\n",
    "\n",
    "def remove_emo_from_utter(txt):\n",
    "    return txt.replace('üôÇ', ' ').replace('üòÆ', ' ').replace('‚òπÔ∏è', ' ').replace('üò°', ' ')\n",
    "\n",
    "def remove_emoticons(all_utterances):\n",
    "    \n",
    "    new_all_utterances = []\n",
    "    for utter in all_utterances:\n",
    "        new_all_utterances.append(remove_emo_from_utter(utter))\n",
    "    \n",
    "    return new_all_utterances\n",
    "\n",
    "def _size(corpus: dict) -> int:\n",
    "    return sum(corpus.values())\n",
    "\n",
    "def _log_odds(\n",
    "    word: str,\n",
    "    c1: dict,\n",
    "    c2: dict,\n",
    "    bg: dict,\n",
    "    size1: int,\n",
    "    size2: int,\n",
    "    size3: int,\n",
    ") -> float:\n",
    "    numerator_1 = c1[word] + bg[word]\n",
    "    numerator_2 = c2[word] + bg[word]\n",
    "    denom_1 = size1 + size3 - numerator_1\n",
    "    denom_2 = size2 + size3 - numerator_2\n",
    "    raw_logodds = math.log(numerator_1 / denom_1) - math.log(\n",
    "        numerator_2 / denom_2\n",
    "    )\n",
    "    \n",
    "    variance = (1 / numerator_1) + (1 / numerator_2)\n",
    "    return raw_logodds / math.sqrt(variance)\n",
    "\n",
    "def get_log_odds(pred2utts):\n",
    "    \n",
    "    #tokenize\n",
    "    pred2toks = {}\n",
    "    for pred, utts in pred2utts.items():\n",
    "        pred2toks[pred] = []    \n",
    "        for utt in utts:\n",
    "            pred2toks[pred] += [w.lower() for w in nltk.word_tokenize(utt)]\n",
    "            \n",
    "    pred2ratios = {}\n",
    "            \n",
    "    for pred, toks in pred2toks.items():\n",
    "    \n",
    "        toks_rest = []\n",
    "        for pred2, toks2 in pred2toks.items():\n",
    "            if(pred2 != pred):\n",
    "                toks_rest += toks2\n",
    "        \n",
    "        c_1 = dict(Counter(toks))\n",
    "        c_2 = dict(Counter(toks_rest))\n",
    "        c_bg = dict(Counter(toks + toks_rest))\n",
    "        \n",
    "        size1 = _size(c_1)\n",
    "        size2 = _size(c_2)\n",
    "        size3 = _size(c_bg)\n",
    "        \n",
    "        supported_tokens = set(c_1.keys())\n",
    "        supported_tokens &= set(c_2.keys())\n",
    "        supported_tokens &= set(c_bg.keys())\n",
    "        \n",
    "        ratios = []\n",
    "        for tok in supported_tokens:\n",
    "            rat = _log_odds(tok, c_1, c_2, c_bg, size1, size2, size3)\n",
    "            ratios.append((tok, rat))\n",
    "\n",
    "        ratios.sort(key=operator.itemgetter(1), reverse=True)\n",
    "        \n",
    "        pred2ratios[pred] = ratios\n",
    "        \n",
    "    return pred2ratios\n",
    "\n",
    "def print_stats(pred2utts):\n",
    "    \n",
    "    #get counts for each label\n",
    "    print(\"---Count of utterances---\")\n",
    "    for pred, utts in pred2utts.items():\n",
    "        print(pred, len(utts))\n",
    "    \n",
    "    print(\"----Sample Utterances----\")\n",
    "    #get 5 random utterances for each label\n",
    "    for pred, utts in pred2utts.items():\n",
    "        print(pred, utts[:5])\n",
    "    \n",
    "    #get top 5 words for each label\n",
    "    print(\"----Top words for each label----\")\n",
    "    #sorted list of tuples for each pred (word, log odds ratio)\n",
    "    pred2logodds = get_log_odds(pred2utts)\n",
    "    \n",
    "    for pred, logodds in pred2logodds.items():\n",
    "        print(f\"----{pred}----\")\n",
    "        \n",
    "        for tup in logodds[:10]:\n",
    "            print(tup[0], round(tup[1], 3))\n",
    "        \n",
    "def get_pred2utts(modelname, num_utts, rem_emoticons):\n",
    "    \n",
    "    all_utterances = []\n",
    "\n",
    "    for item in all_data:\n",
    "        all_utterances += get_utterances(item)\n",
    "\n",
    "    if(rem_emoticons):\n",
    "        all_utterances = remove_emoticons(all_utterances)\n",
    "\n",
    "    random.shuffle(all_utterances)\n",
    "\n",
    "    print(len(all_utterances), len(all_utterances)/len(all_data))\n",
    "\n",
    "    model_obj = None\n",
    "    if(modelname == 'LIWC'):\n",
    "        model_obj = prediction_models.LIWCModel()\n",
    "    elif(modelname == 'Emoticons'):\n",
    "        model_obj = prediction_models.EmoticonModel()\n",
    "    \n",
    "    assert model_obj\n",
    "\n",
    "    pred2utts = {}\n",
    "\n",
    "    for utt in all_utterances[:num_utts]:    \n",
    "        pred = model_obj.predict(utt)\n",
    "\n",
    "        if(pred not in pred2utts):\n",
    "            pred2utts[pred] = []\n",
    "\n",
    "        pred2utts[pred].append(utt)\n",
    "    \n",
    "    return pred2utts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11919 11.571844660194175\n"
     ]
    }
   ],
   "source": [
    "modelnames = ['LIWC', 'Emoticons']\n",
    "\n",
    "modelname = 'Emoticons'#'LIWC'\n",
    "num_utts = 100000\n",
    "rem_emoticons = False\n",
    "\n",
    "pred2utts = get_pred2utts(modelname, num_utts, rem_emoticons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Count of utterances---\n",
      "Neutral 10055\n",
      "Joy 1458\n",
      "Sadness 241\n",
      "Surprise 124\n",
      "Anger 41\n",
      "----Sample Utterances----\n",
      "Neutral ['Perfect! What would you think about if we divided it up so you could have all 3 firewood then, and we could split water and food? ', \"Would you be willing to give me 3 firewood, I'll give you 3 water or food, which ever you need more and we split the rest. What do you say?\", 'Give 1 package of firewood, 2 packages of water and 1 package of food. Seal this deal Sir.', 'if you take all the water i will need all the firewood and two food. deal?', 'Great, that sounds fair to me. ']\n",
      "Joy ['I am ok with that if i get two waters, just incase i have to put out the fire üôÇ', 'That sounds great! I will submit the deal. Hope you have a nice day and best of luck on your camping trip! üôÇ', \"I can't accept that deal unfortunately. Our campsite requires substantial hiking with a lot of elevation gain. I will need the extra food and water to sustain the hiking. How about I take 2 food packages, 1 water package, and 1 firewood package. The rest can go to you. üôÇ\", \"That's sounds right. Thanks üôÇ\", \"Hi, üôÇ It's nice to meet you as well: I also hope we can work something out: Food is my excess trip priority, What is yours?\"]\n",
      "Sadness [\"So do I. I'm trying to bulk up because I've been skinny all my life. ‚òπÔ∏è Let me just get one please‚òπÔ∏è‚òπÔ∏è‚òπÔ∏è‚òπÔ∏è‚òπÔ∏è‚òπÔ∏è\", \"Sorry, I can't give up all the water. I don't want the kids getting dehydrated. ‚òπÔ∏è\", '‚òπÔ∏èOh, that sounds awful. Are you sure you need all three packages of firewood?', 'Water is extremely important for me as it makes the whole day better in general.‚òπÔ∏è', \"‚òπÔ∏è Why suddenly changed your decision? As you already mentioned, I'll take 3 firewood. 1 pack water. You take other things. If this is not fine, let me know we'll come for an conclusion. \"]\n",
      "Surprise ['üòÆ I see.  I actually need at least two of the waters also.  I can leave you two food, one firewood, and one water.  I have a larger group than you, and I think my need is greater given that we are in desert conditions. Given the need, I submit that this is a fair offer.', 'I can give you 1 of the firewood. I would like to stay warm at night so I want 2. üòÆ', 'Are you most interested in the food? üòÆ', 'Thanks good negotiating with you! üòÆ', 'Staying in state, southern Ohio, known as the Hocking Hills. Bad thing is I forgot to pack my extra water.üòÆ']\n",
      "Anger ['I am going to be respectful and not argue here as they are the rules, you have an agreement. I will say you are comparing yourself to 3 people üò°', 'It will be unacceptable to part with more than one firewood, or else I will eat you, my partner, and your entire camping party. I am a bear. üò°', 'No way that is not fair at all.üò°  You can get 2 waters 1 firewood and one food. That is fair and works out better for you.', 'Good afternoon as wellüôÇüò°', \"Let's hurry because I want to get as far away as possible from girls with an axüò°\"]\n",
      "----Top words for each label----\n",
      "----Neutral----\n",
      "water 4.165\n",
      "? 3.546\n",
      "food 3.408\n",
      "2 3.241\n",
      "firewood 3.184\n",
      "1 2.65\n",
      "and 2.633\n",
      "need 2.31\n",
      "give 2.252\n",
      "3 2.247\n",
      "----Joy----\n",
      "üôÇ 32.322\n",
      "! 5.531\n",
      "hope 2.879\n",
      "buddy 2.716\n",
      "awesome 2.699\n",
      "great 2.576\n",
      "snice 2.407\n",
      "thank 2.372\n",
      "hello 2.103\n",
      "wonderful 2.025\n",
      "----Sadness----\n",
      "‚òπÔ∏è 14.22\n",
      "sorry 2.017\n",
      "spilled 1.838\n",
      "n't 1.652\n",
      "reconsider 1.376\n",
      "not 1.34\n",
      "purifier 1.3\n",
      "stopped 1.3\n",
      "death 1.267\n",
      "suffer 1.211\n",
      "----Surprise----\n",
      "üòÆ 9.827\n",
      "secure 1.473\n",
      "# 1.427\n",
      "bargain 1.427\n",
      "drive 1.427\n",
      "function 1.322\n",
      "awful 1.322\n",
      "snack 1.234\n",
      "insist 1.042\n",
      "upset 1.042\n",
      "----Anger----\n",
      "animal 1.358\n",
      "unacceptable 0.98\n",
      "comparing 0.843\n",
      "covid-19 0.843\n",
      "learning 0.843\n",
      "joking 0.843\n",
      "argument 0.843\n",
      "argue 0.843\n",
      "profanity 0.843\n",
      "aw 0.843\n"
     ]
    }
   ],
   "source": [
    "print_stats(pred2utts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ICT2000/chawla/anaconda3/envs/base_acii/lib/python3.7/site-packages/transformers/models/auto/modeling_auto.py:1010: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "#model_obj = prediction_models.EmotionTwitterDataModel()\n",
    "model_obj = prediction_models.EmotionTwitterDataModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'joy'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_obj.predict('I hope this works!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11919 11.571844660194175\n",
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n"
     ]
    }
   ],
   "source": [
    "num_utts = 100000\n",
    "rem_emoticons = True#True\n",
    "\n",
    "all_utterances = []\n",
    "\n",
    "for item in all_data:\n",
    "    all_utterances += get_utterances(item)\n",
    "\n",
    "if(rem_emoticons):\n",
    "    all_utterances = remove_emoticons(all_utterances)\n",
    "\n",
    "random.shuffle(all_utterances)\n",
    "\n",
    "print(len(all_utterances), len(all_utterances)/len(all_data))\n",
    "\n",
    "pred2utts = {}\n",
    "\n",
    "for i, utt in enumerate(all_utterances[:num_utts]):\n",
    "    if(not i%500):\n",
    "        print(i)\n",
    "    pred = model_obj.predict(utt)\n",
    "\n",
    "    if(pred not in pred2utts):\n",
    "        pred2utts[pred] = []\n",
    "\n",
    "    pred2utts[pred].append(utt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Count of utterances---\n",
      "joy 8576\n",
      "sadness 512\n",
      "anger 2019\n",
      "love 94\n",
      "fear 699\n",
      "surprise 17\n",
      "thirst 1\n",
      "hunger 1\n",
      "----Sample Utterances----\n",
      "joy ['Deal with ok but I need 1 water.', 'Hello there, How would you feel about trading supplies in this manner. 2 Water for me and 2 food , while you get 1 Food , 1 Water , and 3 Firewood? ', 'Well we do have the starter kit, but ok then you can have 1 water, 2 firewood and all the food.  I feel generous today ', 'For sure.. I am just busy planning and getting supplies - do not want to forget anything.  ', 'funnny you but no. so what else will i be left with if i give you those. okay let say i get 2 food, 2 firewood and 1 water.']\n",
      "sadness ['I am old. Old people need hydration, more than younger people. Are you younger?', 'Thank you very much. I am anemic so it helps to have all the firewood to keep warm. ', \"O wow.  I'm sorry to here that. I can give you all my firewood and a food if you can give me all your water. \", 'Good! So I primarily need food, as our freezer stopped working so most of our food went bad. What do you need?', \"I really need a lot of firewood because i'm camping in a damp and cold region and need a source of heat at all times.\"]\n",
      "anger ['Tent camping has its drawbacks- What do you have in terms of the quantity of firewood you would be willing to come off of?  ', 'I have a poly-urea problem so i need 3 water package', \"I can deal with that. I'd rather a little thirst than being cold.\", \"I don't need much firewood\", 'I will let you have 2 firewood if you let me have 3 food, 2 water, and 1 firewood.']\n",
      "love [\"I too love a hot cocoa or tea, so we'll definitely need water, firewood is next up, and food is obvious   I think we can take as much as we are allowed. If you wanted, I could take all the food, we could split the water, and you could take all or most of the firewood?\", 'Oh you are a very kind negotiator. ', \"I take it we're both craving the firewood, huh? hehe Well, how about food and water? I like those both too, probably more than firewood.\", \"Unfortunately, I need the firewood to make campfires. Since you are planning to cook a romantic camping meal, don't you need food?\", \"As for the water, I would love to get 2 packages if you don't need the extra, because the weather is expected to be very hot where I'm going, and I am prone to dehydration :(   \"]\n",
      "fear [\"The food situation has me a little nervous.  I've been worried about how many small animals will be in the area due to the rising waters.  I hope some stuck around, but I will see when I get there.  I also read how a terrible disease is killing some of the vegetation in spots around where I will be going.  It is some sort of fungus that is coming up due to it being so wet.\", 'how many water you need?', 'we were planning on doing a lot of hiking. Due to this we will need extra food and water, how about I take all the extra food and 1 of the water, you can have the rest? ', 'That;s going to be tough on us, we got some long hikes planned and really need to stay hydrate.  Will all of the cousins and family be hiking with you?  ', \"Yah we have a few things planned. One of the things they are looking forward to is reading scary stories by the campfire and making s'mores\"]\n",
      "surprise [\"Hi there! Curious as to what's on your mind regarding each item. I have my own preferences, but will share after you.\", 'I could give you two extra food and fire wood. but i really need some of that water, the lake whater here is blue green and smells funny', \"Yes, that's the plan. By the way, what do you need all that food for? You didn't say. I'm just curious.\", 'yeah it is very interesting to hear about ghost stories', 'that would be amazing!, hank you so much']\n",
      "thirst ['Do you mind if I get one third of the water supplies? I might feel thirsty after hiking.']\n",
      "hunger ['Hi, I need the all food package. I will frequently feel hungry']\n",
      "----Top words for each label----\n",
      "----joy----\n",
      "! 10.029\n",
      "good 8.77\n",
      "great 8.197\n",
      "you 8.091\n",
      "hello 8.007\n",
      "sounds 7.826\n",
      "ok 6.937\n",
      "that 6.206\n",
      "okay 5.895\n",
      "excited 5.475\n",
      "----sadness----\n",
      "sorry 10.208\n",
      "unfortunately 4.563\n",
      "dehydrated 3.67\n",
      "need 2.948\n",
      "low 2.895\n",
      "terrible 2.811\n",
      "suffer 2.699\n",
      "lost 2.67\n",
      "anemic 2.61\n",
      "hear 2.52\n",
      "----anger----\n",
      "cold 10.842\n",
      "firewood 6.341\n",
      "no 5.862\n",
      "need 5.627\n",
      "2 5.481\n",
      "thirsty 4.48\n",
      "1 4.261\n",
      "unfair 4.076\n",
      "hungry 4.01\n",
      "water 3.859\n",
      "----love----\n",
      "hot 5.799\n",
      "generous 2.116\n",
      "lovely 1.568\n",
      "hotter 1.438\n",
      "liking 1.343\n",
      "memory 1.343\n",
      "stew 1.052\n",
      "where 1.029\n",
      "during 0.97\n",
      "afford 0.959\n",
      "----fear----\n",
      "worried 8.669\n",
      "afraid 7.01\n",
      "concerned 4.269\n",
      "dark 3.85\n",
      "scared 3.791\n",
      "'m 3.075\n",
      "wet 2.661\n",
      "area 2.623\n",
      "risk 2.452\n",
      "stranded 2.401\n",
      "----surprise----\n",
      "funny 1.927\n",
      "interesting 1.354\n",
      "surprise 1.077\n",
      "ha 1.033\n",
      "status 0.846\n",
      "ohio 0.846\n",
      "blue 0.846\n",
      "world 0.766\n",
      "essentially 0.697\n",
      "cave 0.697\n",
      "----thirst----\n",
      "third 0.339\n",
      "after 0.174\n",
      "thirsty 0.171\n",
      "mind 0.113\n",
      "might 0.106\n",
      "feel 0.094\n",
      "hiking 0.083\n",
      "supplies 0.068\n",
      "one 0.036\n",
      "if 0.028\n",
      "----hunger----\n",
      "frequently 0.462\n",
      "hungry 0.115\n",
      "feel 0.095\n",
      "package 0.065\n",
      "hi 0.052\n",
      "will 0.027\n",
      "all 0.026\n",
      "need 0.018\n",
      "i 0.013\n",
      "food 0.011\n"
     ]
    }
   ],
   "source": [
    "print_stats(pred2utts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.4.2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
