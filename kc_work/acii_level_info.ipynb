{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import matplotlib.pyplot as plt \n",
    "import emoji\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "import copy\n",
    "import liwc\n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Alright..Do we create one big file or smaller files? I guess one bigger file is better, we can break it down later as required.\n",
    "\n",
    "Datapoint level analysis mostly: so 2 rows per dialogue...2060 rows in total.\n",
    "\n",
    "Variables:\n",
    "\n",
    "Include all gale-level variables: Demographics, emoticons, liwc, strategies, integrative potential, outcome variables for self and the partner, and joint points, someone-walks-away, guessing partner outcomes, \n",
    "\n",
    "What else?\n",
    "\n",
    "total pauses..normalized by word count may be, \n",
    "Emotion predictions from a pre-trained model: overall counts, counts for two halves of the conversation, .for each individual, match-mismatch: get an average emotion - > overall, from the two halves..and then build the matching variables.\n",
    "\n",
    "4*4 = 16 matching variables .these are gonna be joint variables that describe the match is present or not.\n",
    "\n",
    "a, b, c, d\n",
    "axa, axb, axc, axd\n",
    "bxb, bxc, bxd\n",
    "cxc, cxd,\n",
    "dxd\n",
    "\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dialog_ann_data(dialog):\n",
    "    #print(dialog)\n",
    "    assert len(dialog) > 0\n",
    "    did = dialog[0][0]\n",
    "    for item in dialog:\n",
    "        assert did == item[0]\n",
    "        \n",
    "    info = {\n",
    "        'agent_1': {},\n",
    "        'agent_2': {}\n",
    "    }\n",
    "    \n",
    "    for item in dialog:\n",
    "        aid = item[1]\n",
    "        labels = item[2].split(\",\")\n",
    "        for label in labels:\n",
    "            if(label not in info[aid]):\n",
    "                info[aid][label] = 0\n",
    "            info[aid][label] += 1\n",
    "    \n",
    "    return info\n",
    "\n",
    "def get_ann_data(input_files):\n",
    "    \"\"\"\n",
    "    dict from dialogue id to all the info of that dialogue.\n",
    "    \"\"\"\n",
    "    did2info = {}\n",
    "    \n",
    "    extra_utterances = ['Submit-Deal', 'Accept-Deal', 'Reject-Deal', 'Walk-Away', 'Submit-Post-Survey']\n",
    "    \n",
    "    for fname in input_files:\n",
    "        print(fname)\n",
    "        df = pd.read_csv(fname)\n",
    "        dat = pd.DataFrame.to_dict(df, orient=\"records\")\n",
    "        \n",
    "        cur_dialog = []\n",
    "        cur_id = -1\n",
    "        \n",
    "        for i, item in enumerate(dat):\n",
    "            if((item[\"DialogueId\"] != item[\"DialogueId\"]) or (item[\"Utterance\"] in extra_utterances)):\n",
    "                continue\n",
    "            \n",
    "            #valid item\n",
    "            this_id = item[\"DialogueId\"]\n",
    "            if((this_id != cur_id) and cur_dialog):\n",
    "                #found new id\n",
    "                cur_data = get_dialog_ann_data(cur_dialog[:])\n",
    "                did2info[int(cur_id)] = cur_data\n",
    "                cur_dialog = []\n",
    "\n",
    "            if(isinstance(item[\"Labels\"], str)):\n",
    "                assert isinstance(item[\"Labels\"], str) and len(item[\"Labels\"])>0, i\n",
    "                this_item = [item[\"DialogueId\"], item[\"AgentID\"], item[\"Labels\"]]\n",
    "                cur_dialog.append(this_item)\n",
    "                cur_id = this_id\n",
    "\n",
    "        if(cur_dialog):\n",
    "            cur_data = get_dialog_ann_data(cur_dialog[:])\n",
    "            did2info[int(cur_id)] = cur_data\n",
    "            cur_dialog = []\n",
    "            \n",
    "    return did2info\n",
    "\n",
    "\n",
    "#liwc setup\n",
    "parse, category_names = liwc.load_token_parser('/home/ICT2000/chawla/Documents/work/CSCI662/project-EMNLP2020/main/resources/LIWC2015_English.dic')\n",
    "category_names = sorted(category_names)\n",
    "\n",
    "def get_wid_liwc_data(wid, item):\n",
    "    \n",
    "    wid_info = {}\n",
    "    \n",
    "    all_text = \"\"\n",
    "    for act in item[\"acts\"]:\n",
    "        if((act['id'] == wid) and (act['text'] not in ['Submit-Deal', 'Accept-Deal', 'Reject-Deal', 'Walk-Away', 'Submit-Post-Survey'])):\n",
    "            all_text += \" \" + act['text']\n",
    "            \n",
    "    tokens = [w.lower() for w in nltk.word_tokenize(all_text)]\n",
    "    feat_dict = dict(Counter(category for token in tokens for category in parse(token)))\n",
    "    \n",
    "    for fname in category_names:\n",
    "        fval = 0\n",
    "        \n",
    "        if(fname in feat_dict):\n",
    "            fval = feat_dict[fname]\n",
    "\n",
    "        wid_info[\"LIWC-\" + fname.replace(\" \", \"-\").replace(\"(\", \"\").replace(\")\", \"\")] = fval\n",
    "        \n",
    "    return wid_info\n",
    "\n",
    "def get_dialog_liwc_data(dialog):\n",
    "    \n",
    "    info = {\n",
    "        'agent_1': get_wid_liwc_data(\"mturk_agent_1\", dialog),\n",
    "        'agent_2': get_wid_liwc_data(\"mturk_agent_2\", dialog)\n",
    "    }\n",
    "    \n",
    "    return info\n",
    "\n",
    "def get_liwc_data(all_data):\n",
    "    \"\"\"\n",
    "    dict from dialogue id to all the info of that dialogue.\n",
    "    \"\"\"\n",
    "    \n",
    "    did2liwcinfo = {}\n",
    "    \n",
    "    for item in all_data:\n",
    "        \n",
    "        did = item['dialogue_id']\n",
    "        did2liwcinfo[did] = get_dialog_liwc_data(item)\n",
    "    \n",
    "    return did2liwcinfo\n",
    "\n",
    "#OTHER FUNCTIONS\n",
    "def get_ann_counts(did, wid, label):\n",
    "    \n",
    "    key = 'agent_1'\n",
    "    if('agent_2' in wid):\n",
    "        key = 'agent_2'\n",
    "    \n",
    "    if(label in did2info[did][key]):\n",
    "        return did2info[did][key][label]\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def get_individual_annotation(item, wid):\n",
    "    \"\"\"\n",
    "    look at the dialogue, get the id, and extract the annotation counts for wid user from that id.\n",
    "    \"\"\"\n",
    "    labels = ['Small-talk', 'Required-self', 'Required-other', 'Not-Required', 'Preference-elicitation', \n",
    "              'Undervalue-Other-Requirement', 'Vouching-for-fairness']\n",
    "    \n",
    "    did = item['dialogue_id']\n",
    "    \n",
    "    ann_counts = {}\n",
    "    \n",
    "    if(did in did2info):\n",
    "        for label in labels:\n",
    "            ann_counts[\"Strategy-\" + label] = get_ann_counts(did, wid, label)\n",
    "    else:\n",
    "        for label in labels:\n",
    "            ann_counts[\"Strategy-\" + label] = -1\n",
    "\n",
    "    return ann_counts\n",
    "\n",
    "def get_liwc_counts(did, wid, label):\n",
    "    \n",
    "    key = 'agent_1'\n",
    "    if('agent_2' in wid):\n",
    "        key = 'agent_2'\n",
    "    \n",
    "    assert label in did2liwcinfo[did][key]\n",
    "    return did2liwcinfo[did][key][label]\n",
    "    \n",
    "def get_individual_liwc(item, wid):\n",
    "    \"\"\"\n",
    "    look at the dialogue, get the id, and extract the annotation counts for wid user from that id.\n",
    "    \"\"\"\n",
    "    \n",
    "    did = item['dialogue_id']\n",
    "    \n",
    "    liwc_counts = {}\n",
    "    \n",
    "    for fname in category_names:\n",
    "        label = \"LIWC-\" + fname.replace(\" \", \"-\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        liwc_counts[label] = get_liwc_counts(did, wid, label)\n",
    "            \n",
    "    return liwc_counts\n",
    "\n",
    "def get_worker_qualtrics(item, wid):\n",
    "    \n",
    "    for worker in item[\"workers\"]:\n",
    "        if(worker[\"id\"] == wid):\n",
    "            return item[\"qualtrics\"][worker[\"worker_id\"]]\n",
    "\n",
    "def get_education_score(qualtrics):\n",
    "    \n",
    "    key2score = {\n",
    "        'Some high school, no diploma': 1,\n",
    "        'High school graduate / GED': 2,\n",
    "        'Some 2 year college, no degree': 3,\n",
    "        \"Some 2 year college, associate's degree\": 4,\n",
    "        \"Some 4 year college, no degree\": 5,\n",
    "        \"Some 4 year college, bachelor's degree\": 6,\n",
    "        \"Master's degree\": 7,\n",
    "        \"Doctorate degree\": 8,\n",
    "        \"Trade school\": -1,\n",
    "    }\n",
    "    \n",
    "    return key2score[qualtrics['Education']]\n",
    "\n",
    "def get_SVO_label(qualtrics):\n",
    "    \"\"\"\n",
    "    https://static1.squarespace.com/static/523f28fce4b0f99c83f055f2/t/56c794cdf8baf3ae17cf188c/1455920333224/Triple+Dominance+Measure+of+SVO.pdf\n",
    "    \"\"\"\n",
    "    SVOans = [qualtrics[\"SVO \" + str(i)] for i in range(1, 13)]\n",
    "    \n",
    "    prosocial = set([\"You get: 480, Other gets 480\", \"You get: 490, Other gets 490\", \"You get: 500, Other gets 500\", \n",
    "                \"You get: 510, Other gets 510\", \"You get: 520, Other gets 520\", \"You get: 440, Other gets 440\"])\n",
    "\n",
    "    individualistic = set([\"You get: 520, Other gets 300\", \"You get: 560, Other gets 300\", \"You get: 570, Other gets 300\",\n",
    "                      \"You get: 550, Other gets 300\", \"You get: 530, Other gets 320\", \"You get: 580, Other gets 320\",\n",
    "                      \"You get: 540, Other gets 300\", \"You get: 470, Other gets 300\", \"You get: 540, Other gets 280\"])\n",
    "\n",
    "    competitive = set([\"You get: 480, Other gets 180\", \"You get: 500, Other gets 100\", \"You get: 460, Other gets 100\",\n",
    "                  \"You get: 520, Other gets 120\", \"You get: 480, Other gets 100\", \"You get: 510, Other gets 110\",\n",
    "                  \"You get: 330, Other gets 110\", \"You get: 490, Other gets 90\", \"You get: 480, Other gets 80\"])\n",
    "    \n",
    "    all_choices = prosocial|individualistic|competitive\n",
    "    \n",
    "    pCount, iCount, cCount = 0, 0, 0\n",
    "    \n",
    "    for ans in SVOans:\n",
    "        assert ans in all_choices, ans\n",
    "        \n",
    "        if(ans in prosocial):\n",
    "            pCount += 1\n",
    "            if(pCount > 6):\n",
    "                return \"Prosocial\"\n",
    "        elif(ans in individualistic):\n",
    "            iCount += 1\n",
    "            if(iCount > 6):\n",
    "                return \"Proself\"\n",
    "                #return \"Individualistic\"\n",
    "        elif(ans in competitive):\n",
    "            cCount += 1\n",
    "            if(cCount > 6):\n",
    "                return \"Proself\"\n",
    "                #return \"Competitive\"\n",
    "    \n",
    "    #no category reached 6\n",
    "    return \"Unclassified\"\n",
    "\n",
    "def get_big_five_scores(qualtrics):\n",
    "    \"\"\"\n",
    "    https://gosling.psy.utexas.edu/scales-weve-developed/ten-item-personality-measure-tipi/ten-item-personality-inventory-tipi/\n",
    "    https://www.psychologytoday.com/us/blog/darwins-subterranean-world/201810/take-quick-personality-test\n",
    "    \"\"\"\n",
    "    \n",
    "    bigFiveAns = [qualtrics[\"Big Five_\" + str(i)] for i in range(1,11)]\n",
    "    bigFiveQues = ['Extraverted, enthusiastic', 'Critical, quarrelsome', 'Dependable, self-disciplined',\n",
    "                    'Anxious, easily upset', 'Open to new experiences, complex', 'Reserved, quiet',\n",
    "                    'Sympathetic, warm', 'Disorganized, careless', 'Calm, emotionally stable', \n",
    "                    'Conventional, uncreative']\n",
    "    \n",
    "    numTitles = {\"Disagree Strongly\":1, \"Disagree Moderately\":2, \"Disagree a little\":3, \"Neither agree or disagree\":4,\n",
    "            \"Agree a little\":5, \"Agree Moderately\":6, \"Agree Strongly\":7}\n",
    "    \n",
    "    BB = {}\n",
    "    for ques, ans in zip(bigFiveQues, bigFiveAns):\n",
    "        BB[ques] = numTitles[ans]\n",
    "        \n",
    "    BB[\"Critical, quarrelsome\"] = 8 - BB[\"Critical, quarrelsome\"]    \n",
    "    BB[\"Anxious, easily upset\"] = 8 - BB[\"Anxious, easily upset\"]     \n",
    "    BB[\"Reserved, quiet\"] = 8 - BB[\"Reserved, quiet\"]            \n",
    "    BB[\"Disorganized, careless\"] = 8 - BB[\"Disorganized, careless\"]  \n",
    "    BB[\"Conventional, uncreative\"] = 8 - BB[\"Conventional, uncreative\"]\n",
    "    \n",
    "    big_five_scores = {\n",
    "    \n",
    "    \"BigFive-Extraversion\": (BB[\"Extraverted, enthusiastic\"] + BB[\"Reserved, quiet\"])/2,\n",
    "    \"BigFive-Agreeableness\": (BB[\"Critical, quarrelsome\"] + BB[\"Sympathetic, warm\"])/2,\n",
    "    \"BigFive-Conscientiousness\": (BB[\"Dependable, self-disciplined\"] + BB[\"Disorganized, careless\"])/2,\n",
    "    \"BigFive-Emotional-Stability\": (BB[\"Anxious, easily upset\"] + BB[\"Calm, emotionally stable\"])/2,\n",
    "    \"BigFive-Openness-to-Experiences\": (BB[\"Open to new experiences, complex\"] + BB[\"Conventional, uncreative\"])/2\n",
    "    \n",
    "    }\n",
    "    \n",
    "    return big_five_scores\n",
    "\n",
    "def get_individual_distal(item, wid):\n",
    "    \"\"\"\n",
    "    This is the qualtrics stuff.\n",
    "    \"\"\"\n",
    "    qualtrics = get_worker_qualtrics(item, wid)\n",
    "    \n",
    "    usable_data = {}\n",
    "    \n",
    "    usable_data[\"Age\"] = int(qualtrics['Age'])\n",
    "    usable_data[\"Gender\"] = qualtrics['Gender']\n",
    "    usable_data[\"Ethnicity\"] = qualtrics[\"Race/Ethnicity\"]\n",
    "    \n",
    "    usable_data[\"Education\"] = get_education_score(qualtrics)\n",
    "    usable_data[\"SVO\"] = get_SVO_label(qualtrics)\n",
    "    \n",
    "    big_five_scores = get_big_five_scores(qualtrics)\n",
    "    for attribute, score in big_five_scores.items():\n",
    "        usable_data[attribute] = score\n",
    "        \n",
    "    return usable_data\n",
    "\n",
    "def get_emoticon_counts(text):\n",
    "    \"\"\"\n",
    "    'üôÇ', '‚òπÔ∏è', 'üòÆ', 'üò°'\n",
    "    \"\"\"\n",
    "    counts = {\n",
    "        'Num-happy': text.count('üôÇ'),\n",
    "        'Num-sad': text.count('‚òπÔ∏è'),\n",
    "        'Num-surprise': text.count('üòÆ'),\n",
    "        'Num-angry': text.count('üò°')\n",
    "    }\n",
    "    \n",
    "    return counts\n",
    "\n",
    "def get_aggregate_emotion(this_data, keypart):\n",
    "    \n",
    "    max_val = float('-inf')\n",
    "    \n",
    "    for key, val in this_data.items():\n",
    "        if(keypart in key):\n",
    "            max_val = max(max_val, val)\n",
    "            \n",
    "    max_preds = []\n",
    "    \n",
    "    for key, val in this_data.items():\n",
    "        if(val == max_val):\n",
    "            max_preds.append(key.split('.')[-1])\n",
    "    \n",
    "    random.shuffle(max_preds)\n",
    "    \n",
    "    return max_preds[0]\n",
    "\n",
    "def get_emotion_predictions(item, wid):\n",
    "    \"\"\"\n",
    "    overall + halves emotion-wise counts,\n",
    "    that helps to decide the overall + halves primary emotion label.\n",
    "    \n",
    "    that will later help to decide the match vs mismatch category.\n",
    "    \n",
    "    Model.Overall.Anger\n",
    "    Model.FirstHalf.Anger\n",
    "    Model.SecondHalf.Anger\n",
    "    \n",
    "    Model.Overall.Emotion\n",
    "    Model.FirstHalf.Emotion\n",
    "    Model.SecondHalf.Emotion\n",
    "    \"\"\"\n",
    "    \n",
    "    total_count = 0\n",
    "    \n",
    "    for act in item[\"acts\"]:\n",
    "        if((act['id'] == wid) and (act['text'] not in ['Submit-Deal', 'Accept-Deal', 'Reject-Deal', 'Walk-Away', 'Submit-Post-Survey'])):\n",
    "            total_count += 1\n",
    "    \n",
    "    this_data = {}\n",
    "    labels = ['joy', 'anger', 'sadness', 'love', 'fear', 'surprise', 'neutral']\n",
    "    \n",
    "    for label in labels:\n",
    "        this_data[f'Model.Overall.{label}'] = 0\n",
    "        this_data[f'Model.FirstHalf.{label}'] = 0\n",
    "        this_data[f'Model.SecondHalf.{label}'] = 0\n",
    "    \n",
    "    curr_count = 0\n",
    "    \n",
    "    for act in item[\"acts\"]:\n",
    "        if((act['id'] == wid) and (act['text'] not in ['Submit-Deal', 'Accept-Deal', 'Reject-Deal', 'Walk-Away', 'Submit-Post-Survey'])):\n",
    "            \n",
    "            utterance = act['text'].replace('üôÇ', ' ').replace('üòÆ', ' ').replace('‚òπÔ∏è', ' ').replace('üò°', ' ')\n",
    "            assert utterance in utterance2pred\n",
    "            \n",
    "            prediction = utterance2pred[utterance]\n",
    "            \n",
    "            key = f'Model.Overall.{prediction}'\n",
    "            this_data[key] += 1\n",
    "            \n",
    "            key = f'Model.SecondHalf.{prediction}'\n",
    "            if(curr_count < total_count/2):\n",
    "                key = f'Model.FirstHalf.{prediction}'\n",
    "            this_data[key] += 1\n",
    "            \n",
    "            curr_count += 1\n",
    "            \n",
    "    overall_emotion = get_aggregate_emotion(this_data, 'Overall')\n",
    "    firsthalf_emotion = get_aggregate_emotion(this_data, 'FirstHalf')\n",
    "    secondhalf_emotion = get_aggregate_emotion(this_data, 'SecondHalf') \n",
    "    \n",
    "    this_data['Model.Overall.Emotion'] = overall_emotion\n",
    "    this_data['Model.FirstHalf.Emotion'] = firsthalf_emotion\n",
    "    this_data['Model.SecondHalf.Emotion'] = secondhalf_emotion\n",
    "    \n",
    "    return this_data\n",
    "\n",
    "def get_pauses_info(item, wid):\n",
    "    \"\"\"\n",
    "    basically we have the entire duration..\n",
    "    so get the average duration for each person...normalized by the character length across the complete negotiation.\n",
    "    \n",
    "    How many words do we read per minute? A review and meta-analysis of reading rate: Reading speed 238 wpm\n",
    "    \n",
    "    41.4 wpm: https://www.ratatype.com/learn/average-typing-speed/\n",
    "    \n",
    "    Return the mean pause across all utterances.\n",
    "    \"\"\"\n",
    "    \n",
    "    pauses = []\n",
    "    \n",
    "    total_duration = 0\n",
    "    total_words = 0\n",
    "    \n",
    "    r_speed = 238/60 #words per second\n",
    "    w_speed = 41.4/60 # words per second\n",
    "    \n",
    "    for i, act in enumerate(item[\"acts\"]):\n",
    "        if((act['id'] == wid) and (act['text'] not in ['Submit-Deal', 'Accept-Deal', 'Reject-Deal', 'Walk-Away', 'Submit-Post-Survey'])):\n",
    "            if((i==0) or (item[\"acts\"][i-1]['text'] in ['Submit-Deal', 'Accept-Deal', 'Reject-Deal', 'Walk-Away', 'Submit-Post-Survey'])):\n",
    "                #no previous\n",
    "                duration = act['duration']/1000 #in seconds\n",
    "                w_words = len(nltk.word_tokenize(act['text']))\n",
    "                pause = duration - w_words/w_speed\n",
    "                #print(\"duration, w_words, w_speed, pause\", duration, w_words, w_speed, pause)\n",
    "                pauses.append(pause)\n",
    "            else:\n",
    "                #use previous\n",
    "                duration = act['duration']/1000 #in seconds\n",
    "                w_words = len(nltk.word_tokenize(act['text']))\n",
    "                r_words = len(nltk.word_tokenize(item['acts'][i-1]['text']))\n",
    "                pause = duration - w_words/w_speed - r_words/r_speed\n",
    "                pauses.append(pause)\n",
    "                \n",
    "            total_duration += act['duration']/1000\n",
    "            total_words += len(nltk.word_tokenize(act['text']))\n",
    "    \n",
    "    this_data = {\n",
    "        #'MeanPause': np.mean(pauses)\n",
    "        'Duration-per-word': total_duration/total_words\n",
    "    }\n",
    "    #print(pauses)\n",
    "    return this_data\n",
    "\n",
    "def get_individual_proximal(item, wid):\n",
    "    \"\"\"\n",
    "    These are various features extracted from the conversation and negotiation scenario (proximal)\n",
    "    goes_first, num_words, num_emoticon_anger//etc, walks_away, high_issue, medium_issue, low_issue, \n",
    "    reason category (can you try with simple keywords?) do like topic modelling on the reasons (yesssss)\n",
    "    \"\"\"\n",
    "    individual_proximal_info = {}\n",
    "    \n",
    "    for worker in item[\"workers\"]:\n",
    "        if(worker['id'] == wid):\n",
    "            individual_proximal_info['High_item'] = worker['value2issue']['High']\n",
    "            individual_proximal_info['Medium_item'] = worker['value2issue']['Medium']\n",
    "            individual_proximal_info['Low_item'] = worker['value2issue']['Low']\n",
    "            \n",
    "    for act in item[\"acts\"]:\n",
    "        if(act['text'] not in ['Submit-Deal', 'Accept-Deal', 'Reject-Deal', 'Walk-Away', 'Submit-Post-Survey']):\n",
    "            if(act['id'] == wid):\n",
    "                individual_proximal_info[\"Goes_first\"] = \"yes\"\n",
    "            else:\n",
    "                individual_proximal_info[\"Goes_first\"] = \"no\"\n",
    "            break\n",
    "            \n",
    "    individual_proximal_info[\"Walks_away\"] = \"no\"\n",
    "    for act in item[\"acts\"]:\n",
    "        if(act['text'] == 'Walk-Away'):\n",
    "            if(act['id'] == wid):\n",
    "                individual_proximal_info[\"Walks_away\"] = \"yes\"\n",
    "            break\n",
    "    \n",
    "    all_text = \"\"\n",
    "    for act in item[\"acts\"]:\n",
    "        if((act['id'] == wid) and (act['text'] not in ['Submit-Deal', 'Accept-Deal', 'Reject-Deal', 'Walk-Away', 'Submit-Post-Survey'])):\n",
    "            all_text += \" \" + act['text']\n",
    "    \n",
    "    individual_proximal_info[\"Num_words\"] = len(nltk.word_tokenize(all_text))\n",
    "    \n",
    "    #emoticons\n",
    "    individual_proximal_info.update(get_emoticon_counts(all_text))\n",
    "    \n",
    "    #prediction model for emotion\n",
    "    individual_proximal_info.update(get_emotion_predictions(item, wid))\n",
    "    \n",
    "    #pauses information\n",
    "    individual_proximal_info.update(get_pauses_info(item, wid))\n",
    "    \n",
    "    return individual_proximal_info\n",
    "\n",
    "def get_satisfaction(sat_type):\n",
    "    type2score = {\n",
    "        'Extremely dissatisfied': 1,\n",
    "        'Slightly dissatisfied': 2,\n",
    "        'Undecided': 3,\n",
    "        'Slightly satisfied': 4,\n",
    "        'Extremely satisfied': 5,\n",
    "    }\n",
    "    \n",
    "    return type2score[sat_type]\n",
    "\n",
    "def get_opp_likeness(like_type):\n",
    "    type2score = {\n",
    "        'Extremely dislike': 1,\n",
    "        'Slightly dislike': 2,\n",
    "        'Undecided': 3,\n",
    "        'Slightly like': 4,\n",
    "        'Extremely like': 5,\n",
    "    }\n",
    "    \n",
    "    return type2score[like_type]\n",
    "\n",
    "def get_partner_issue(item, wid, value):\n",
    "    \n",
    "    for worker in item['workers']:\n",
    "        if(worker['id'] != wid):\n",
    "            return worker['value2issue'][value]\n",
    "\n",
    "def get_individual_outcomes(item, wid):\n",
    "    \"\"\"\n",
    "    points scored, satisfaction, likeness, guess partner high, guess partner low.\n",
    "    H:5, M:4, L:3\n",
    "    \"\"\"\n",
    "    individual_outcomes = {}\n",
    "    \n",
    "    #points scored.\n",
    "    someone_walks_away = False\n",
    "    for act in item[\"acts\"]:\n",
    "        if(act['text'] == 'Walk-Away'):\n",
    "            someone_walks_away = True\n",
    "            break\n",
    "    \n",
    "    if(someone_walks_away):\n",
    "        individual_outcomes['Points_scored'] = 5#=one high item\n",
    "    else:\n",
    "        assert item['acts'][-4]['text'] == 'Submit-Deal'\n",
    "        #this is the final deal.\n",
    "        deal = item['acts'][-4]\n",
    "        \n",
    "        if(deal['id'] == wid):\n",
    "            #this worker submitted the deal.\n",
    "            key = 'issue2youget'\n",
    "        else:\n",
    "            #this worker did not submit the deal, so this worker gets whatever they gets\n",
    "            key = 'issue2theyget'\n",
    "            \n",
    "        #get value2issue\n",
    "        for worker in item['workers']:\n",
    "            if(worker['id'] == wid):\n",
    "                value2issue = worker['value2issue']\n",
    "                break\n",
    "                \n",
    "        points = 0\n",
    "        points += 5*int(deal['task_data']['response'][key][value2issue['High']])\n",
    "        points += 4*int(deal['task_data']['response'][key][value2issue['Medium']])\n",
    "        points += 3*int(deal['task_data']['response'][key][value2issue['Low']])\n",
    "        \n",
    "        individual_outcomes['Points_scored'] = points\n",
    "        \n",
    "    #from the post-survey\n",
    "    for act in item['acts']:\n",
    "        if(act['text'] == 'Submit-Post-Survey' and (act['id'] == wid)):\n",
    "            individual_outcomes['Satisfaction'] = get_satisfaction(act['task_data']['response']['satisfaction'])\n",
    "            individual_outcomes['Opponent_likeness'] = get_opp_likeness(act['task_data']['response']['likeness'])\n",
    "            \n",
    "            if(get_partner_issue(item, wid, \"High\") == act['task_data']['response']['partner_highest_item']):\n",
    "                individual_outcomes['Guess_partner_high'] = 'Correct'\n",
    "            else:\n",
    "                individual_outcomes['Guess_partner_high'] = 'Incorrect'\n",
    "            \n",
    "            if(get_partner_issue(item, wid, \"Low\") == act['task_data']['response']['partner_lowest_item']):\n",
    "                individual_outcomes['Guess_partner_low'] = 'Correct'\n",
    "            else:\n",
    "                individual_outcomes['Guess_partner_low'] = 'Incorrect'\n",
    "                \n",
    "    return individual_outcomes\n",
    "\n",
    "def get_individual_info(item, wid):\n",
    "    \"\"\"\n",
    "    individual level information, from all the ends, distal, proximal and outcomes.\n",
    "    \"\"\"\n",
    "    individual_info = {}\n",
    "    individual_info[\"Wid\"] = wid\n",
    "    \n",
    "    individual_info.update(get_individual_distal(item, wid))\n",
    "    individual_info.update(get_individual_proximal(item, wid))\n",
    "    individual_info.update(get_individual_annotation(item, wid))\n",
    "    individual_info.update(get_individual_liwc(item, wid))\n",
    "    individual_info.update(get_individual_outcomes(item, wid))\n",
    "    \n",
    "    return individual_info\n",
    "\n",
    "def get_integrative_potential(individuals_info):\n",
    "    \"\"\"\n",
    "    scenario type\n",
    "    \n",
    "    only 3 categories.\n",
    "    \n",
    "    Integrative Potential:\n",
    "    HH, MM, LL: max score 36, Code: 1\n",
    "    HM, HM, LL/ HH, ML, ML: 39 Code: 2,\n",
    "    HM, ML, HL/HL, MM, HL: 42 Code: 3\n",
    "    \n",
    "    Integrative potential increases with increasing code number. -> continuous.\n",
    "    \"\"\"\n",
    "    \n",
    "    if((individuals_info[0]['Low_item'] == individuals_info[1]['Low_item']) and (individuals_info[0]['Medium_item'] == individuals_info[1]['Medium_item'])):\n",
    "        return 1\n",
    "    \n",
    "    if((individuals_info[0]['Low_item'] == individuals_info[1]['Low_item']) and (individuals_info[0]['High_item'] == individuals_info[1]['Medium_item'])):\n",
    "        return 2\n",
    "    \n",
    "    if((individuals_info[0]['High_item'] == individuals_info[1]['High_item']) and (individuals_info[0]['Medium_item'] == individuals_info[1]['Low_item'])):\n",
    "        return 2\n",
    "    \n",
    "    return 3\n",
    "\n",
    "def get_matching_variables(item, individuals_info, keytype):\n",
    "    \n",
    "    labels = ['joy', 'anger', 'sadness', 'love', 'fear', 'surprise', 'neutral']\n",
    "    \n",
    "    lab2lab = []\n",
    "    for label in labels:\n",
    "        for label2 in labels:\n",
    "            l1, l2 = label, label2\n",
    "            if(l1 > l2):\n",
    "                l1, l2 = label2, label\n",
    "            lab2lab.append(f'{l1}-and-{l2}')\n",
    "    \n",
    "    lab2lab = sorted(list(set(lab2lab)))\n",
    "    \n",
    "    this_data = {}\n",
    "    \n",
    "    for key in lab2lab:\n",
    "        this_data[f'Matching.{keytype}.{key}'] = 0\n",
    "    \n",
    "    #make key\n",
    "    kk = f'Model.{keytype}.Emotion'\n",
    "    label, label2 = individuals_info[0][kk], individuals_info[1][kk]\n",
    "    \n",
    "    l1, l2 = label, label2\n",
    "    if(l1 > l2):\n",
    "        l1, l2 = label2, label\n",
    "    this_key = f'{l1}-and-{l2}'\n",
    "    \n",
    "    this_key = f'Matching.{keytype}.{this_key}'\n",
    "    \n",
    "    assert this_key in this_data\n",
    "    this_data[this_key] = 1\n",
    "    \n",
    "    return this_data\n",
    "\n",
    "def get_diadic_info(item, index, individuals_info):\n",
    "    \"\"\"\n",
    "    combining continuous, categorical individual variables, \n",
    "    scenario type.\n",
    "    \"\"\"\n",
    "    diadic_info = {}\n",
    "    \n",
    "    diadic_info[\"Conversation-id\"] = index\n",
    "    \n",
    "    #scenario type\n",
    "    diadic_info[\"Integrative-potential\"] = get_integrative_potential(individuals_info)\n",
    "    \n",
    "    #Walk away\n",
    "    dkey = \"Someone-Walks-Away\"\n",
    "    ikey = \"Walks_away\"\n",
    "    if(individuals_info[0][ikey] == \"yes\" or individuals_info[1][ikey] == \"yes\"):\n",
    "        diadic_info[dkey] = \"yes\"\n",
    "    else:\n",
    "        diadic_info[dkey] = \"no\"\n",
    "        \n",
    "    #total points scored.\n",
    "    dkey = \"Total-points-scored\"\n",
    "    ikey = \"Points_scored\"\n",
    "    diadic_info[dkey] = individuals_info[0][ikey] + individuals_info[1][ikey]\n",
    "    \n",
    "    #matching variables\n",
    "    diadic_info.update(get_matching_variables(item, individuals_info, \"Overall\"))\n",
    "    diadic_info.update(get_matching_variables(item, individuals_info, \"FirstHalf\"))\n",
    "    diadic_info.update(get_matching_variables(item, individuals_info, \"SecondHalf\"))\n",
    "    \n",
    "    return diadic_info\n",
    "\n",
    "def intermix_individuals_info(individuals_info):\n",
    "    individuals_info_mixed = [copy.deepcopy(ii) for ii in individuals_info]\n",
    "    \n",
    "    for i in range(2):\n",
    "        partner_i = 1-i\n",
    "        for key, value in individuals_info[partner_i].items():\n",
    "            individuals_info_mixed[i]['Partner.' + key] = value\n",
    "            \n",
    "    return individuals_info_mixed\n",
    "\n",
    "def get_acii_point_info(item, index):\n",
    "    \n",
    "    ids = [\"mturk_agent_1\", \"mturk_agent_2\"]\n",
    "    #individual info\n",
    "    individuals_info = [get_individual_info(item, wid) for wid in ids]\n",
    "    \n",
    "    #diadic variables\n",
    "    diadic_info = get_diadic_info(item, index, individuals_info)\n",
    "    \n",
    "    #intermix: Use a prefix like Partner. for partner's info.\n",
    "    individuals_info_mixed = intermix_individuals_info(individuals_info)\n",
    "    \n",
    "    #add diadic.\n",
    "    for i in range(2):\n",
    "        individuals_info_mixed[i].update(diadic_info)\n",
    "        \n",
    "    #once inter-mixed + diadic, becomes the final datapoint\n",
    "    acii_point_info = individuals_info_mixed\n",
    "    return acii_point_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030\n",
      "dict_keys(['convo_is_finished', 'world_tag', 'bad_workers', 'acts', 'turns', 'workers', 'fpath', 'qualtrics', 'dialogue_id'])\n"
     ]
    }
   ],
   "source": [
    "in_f = \"/home/ICT2000/chawla/Documents/internship2020/git_repo/storage/airtable/all_data-1030-shuffled.json\"\n",
    "with open(in_f) as f:\n",
    "    all_data = json.load(f)\n",
    "    \n",
    "print(len(all_data))\n",
    "print(all_data[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ICT2000/chawla/Documents/internship2020/git_repo/storage/airtable/accumulate/sample-5-kushal.csv\n",
      "/home/ICT2000/chawla/Documents/internship2020/git_repo/storage/airtable/accumulate/sample-200-kushal-Grid view-v2.csv\n",
      "/home/ICT2000/chawla/Documents/internship2020/git_repo/storage/airtable/accumulate/sample-200-rene-Grid view.csv\n",
      "/home/ICT2000/chawla/Documents/internship2020/git_repo/storage/airtable/accumulate/sample-200-jaysa-Grid view.csv\n",
      "/home/ICT2000/chawla/Documents/internship2020/git_repo/storage/airtable/accumulate/sample-next-10-kushal-Grid view_v2.csv\n"
     ]
    }
   ],
   "source": [
    "input_files = [\n",
    "    \"/home/ICT2000/chawla/Documents/internship2020/git_repo/storage/airtable/accumulate/sample-5-kushal.csv\",\n",
    "    \"/home/ICT2000/chawla/Documents/internship2020/git_repo/storage/airtable/accumulate/sample-200-kushal-Grid view-v2.csv\",\n",
    "    \"/home/ICT2000/chawla/Documents/internship2020/git_repo/storage/airtable/accumulate/sample-200-rene-Grid view.csv\",\n",
    "    \"/home/ICT2000/chawla/Documents/internship2020/git_repo/storage/airtable/accumulate/sample-200-jaysa-Grid view.csv\",\n",
    "    \"/home/ICT2000/chawla/Documents/internship2020/git_repo/storage/airtable/accumulate/sample-next-10-kushal-Grid view_v2.csv\"\n",
    "]\n",
    "\n",
    "did2info = get_ann_data(input_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#liwc setup\n",
    "did2liwcinfo = get_liwc_data(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#emotion predictions\n",
    "with open('/home/ICT2000/chawla/Documents/internship2020/git_repo/storage/emotion_predictions.json') as json_file:\n",
    "    utterance2pred = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "acii_level_info = [] # list of dicts\n",
    "for ix, item in enumerate(all_data, start=1):\n",
    "    \n",
    "    #list of size two, one for each participant, add annos whenever available, otherwise keeep None.\n",
    "    this_info = get_acii_point_info(item, ix)\n",
    "    acii_level_info += this_info\n",
    "        \n",
    "df = pd.DataFrame.from_dict(acii_level_info)\n",
    "df.to_csv('/home/ICT2000/chawla/Documents/internship2020/git_repo/storage/acii-level-info.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Wid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
